{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPu9QzPnL6mGTHXFWHS6na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoctorVinay8097/DV-lab/blob/main/DV_Lab_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Object detection using Yolo algorithm**"
      ],
      "metadata": {
        "id": "6s6Fd-coKW7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object detection** is a computer vision task that involves locating and classifying objects within an image or a video. It can be approached using two main methodologies: single-stage detectors and two-stage detectors.\n",
        "\n",
        "**Single-Stage Detectors:**\n",
        "\n",
        "Single-stage detectors aim to perform object detection in a single pass through the neural network, making them faster and more suitable for real-time applications.\n",
        "\n",
        "**Two-Stage Detectors:**\n",
        "\n",
        "Two-stage detectors, on the other hand, follow a more complex two-step process: region proposal and object classification. They are known for their accuracy and are commonly used in applications where high precision is essential.\n"
      ],
      "metadata": {
        "id": "Zf6hO9XUKlU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Yolo algorithm**\n",
        "\n",
        "**YOLO**, which stands for \"You Only Look Once,\" is a real-time object detection algorithm that revolutionized the field of computer vision. It was first introduced by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi in 2015.\n",
        "\n",
        "Here's a brief overview of the YOLO algorithm:\n",
        "\n",
        "* Single-Pass Object Detection:\n",
        "\n",
        "YOLO is a single-stage object detection algorithm, which means it performs both object localization and classification in a single pass through the neural network.  \n",
        "\n",
        "* Grid-Based Approach:\n",
        "\n",
        "YOLO divides the input image into a grid of cells, typically, 7x7 or 13x13 cells. Each cell is responsible for predicting objects that fall within it.\n",
        "\n",
        "* Bounding Box Prediction:\n",
        "\n",
        "For each cell, YOLO predicts bounding boxes. Each bounding box is characterized by its (x, y) coordinates, width (w), height (h), and a confidence score.\n",
        "\n",
        "* Class Prediction:\n",
        "\n",
        "YOLO simultaneously predicts the class probabilities for each bounding box. The number of classes is predefined (e.g., 20 classes for COCO dataset).\n",
        "\n",
        "* Anchor Boxes:\n",
        "\n",
        "YOLO uses anchor boxes to improve localization. These anchor boxes are predefined shapes and aspect ratios that help predict bounding boxes of various sizes and shapes for objects.\n",
        "\n",
        "* Non-Maximum Suppression:\n",
        "\n",
        "After making predictions, YOLO uses non-maximum suppression (NMS) to filter out redundant bounding boxes. This ensures that only the most confident and accurate boxes are retained."
      ],
      "metadata": {
        "id": "TlOj5spnLQhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLOv3 model\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "\n",
        "# Load COCO class names\n",
        "with open('coco.names', 'r') as f:\n",
        "    classes = f.read().strip().split('\\n')\n",
        "\n",
        "# Load the sample image (replace 'sample.jpg' with your image file)\n",
        "image = cv2.imread('sample.jpg')\n",
        "height, width, _ = image.shape\n",
        "\n",
        "# Create a blob from the image\n",
        "blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "net.setInput(blob)\n",
        "\n",
        "# Get output layer names\n",
        "layer_names = net.getUnconnectedOutLayersNames()\n",
        "\n",
        "# Run YOLO object detection\n",
        "outs = net.forward(layer_names)\n",
        "\n",
        "class_ids = []\n",
        "confidences = []\n",
        "boxes = []\n",
        "\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "\n",
        "        if confidence > 0.5:  # Adjust confidence threshold as needed\n",
        "            center_x, center_y = int(detection[0] * width), int(detection[1] * height)\n",
        "            w, h = int(detection[2] * width), int(detection[3] * height)\n",
        "            x, y = center_x - w // 2, center_y - h // 2\n",
        "\n",
        "            class_ids.append(class_id)\n",
        "            confidences.append(float(confidence))\n",
        "            boxes.append([x, y, w, h])\n",
        "\n",
        "# Non-maximum suppression\n",
        "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "# Draw bounding boxes and labels\n",
        "for i in indices:\n",
        "    i = i[0]\n",
        "    box = boxes[i]\n",
        "    x, y, w, h = box\n",
        "    label = str(classes[class_ids[i]])\n",
        "    confidence = confidences[i]\n",
        "\n",
        "    color = (0, 255, 0)  # Green\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "    cv2.putText(image, f'{label} {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "4rAeZxtfLO1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, Replace **'yolov3.weights', 'yolov3.cfg', 'coco.names', and 'sample.jpg'** with the appropriate paths to your YOLO model files and sample image. You can download the YOLOv3 pre-trained weights and configuration file from the official YOLO website.\n"
      ],
      "metadata": {
        "id": "bGnhFHaGJ8-E"
      }
    }
  ]
}